{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-14T13:09:40.651909Z",
     "start_time": "2025-04-14T13:09:40.628556Z"
    }
   },
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from itertools import product\n",
    "\n",
    "from utils import *\n",
    "from loader.fi_loader import *\n",
    "from models.cnn_lstm import CNN_LSTM\n",
    "from models.cnn import CNN\n",
    "from models.lstm import LSTM\n",
    "from models.mlp import MLP\n",
    "from train import batch_train"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "70e9eb305eacec91",
   "metadata": {},
   "source": [
    "# Train CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551855d1df8e63d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-13T23:51:10.722526Z",
     "start_time": "2025-04-13T23:50:18.859806Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Epoch 1/30,\n",
      "        Train Loss: 0.9663, Train Acc:  0.6073,\n",
      "        Validation Loss: 0.9558, Validation Acc:  0.5922,\n",
      "        Duration: 0:00:26.485048\n",
      "\n",
      "        Epoch 2/30,\n",
      "        Train Loss: 0.9171, Train Acc:  0.6327,\n",
      "        Validation Loss: 0.9570, Validation Acc:  0.5855,\n",
      "        Duration: 0:00:21.870410\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:51, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 14\u001B[0m\n\u001B[1;32m     11\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m     12\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(lob_model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0001\u001B[39m)\n\u001B[0;32m---> 14\u001B[0m \u001B[43mbatch_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlob_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mEPOCHS\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/AFM423_FinalProject/train.py:35\u001B[0m, in \u001B[0;36mbatch_train\u001B[0;34m(model_name, model, criterion, optimizer, train_loader, val_loader, epochs)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# Backward and optimize\u001B[39;00m\n\u001B[1;32m     34\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m---> 35\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     36\u001B[0m train_loss\u001B[38;5;241m.\u001B[39mappend(loss\u001B[38;5;241m.\u001B[39mitem())\n\u001B[1;32m     37\u001B[0m tmp_acc \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcount_nonzero(torch\u001B[38;5;241m.\u001B[39margmax(outputs, dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m targets)\u001B[38;5;241m.\u001B[39mitem()\u001B[38;5;241m/\u001B[39mtargets\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m~/Desktop/Academic/4B/CS 480/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:493\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    488\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    489\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m    490\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    491\u001B[0m             )\n\u001B[0;32m--> 493\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    494\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[1;32m    496\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[0;32m~/Desktop/Academic/4B/CS 480/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:91\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m     89\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m     90\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[0;32m---> 91\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[0;32m~/Desktop/Academic/4B/CS 480/.venv/lib/python3.13/site-packages/torch/optim/adam.py:244\u001B[0m, in \u001B[0;36mAdam.step\u001B[0;34m(self, closure)\u001B[0m\n\u001B[1;32m    232\u001B[0m     beta1, beta2 \u001B[38;5;241m=\u001B[39m group[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbetas\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    234\u001B[0m     has_complex \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_group(\n\u001B[1;32m    235\u001B[0m         group,\n\u001B[1;32m    236\u001B[0m         params_with_grad,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    241\u001B[0m         state_steps,\n\u001B[1;32m    242\u001B[0m     )\n\u001B[0;32m--> 244\u001B[0m     \u001B[43madam\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    245\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams_with_grad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    246\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    247\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    248\u001B[0m \u001B[43m        \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    249\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    250\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    251\u001B[0m \u001B[43m        \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mamsgrad\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m        \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mweight_decay\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    257\u001B[0m \u001B[43m        \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43meps\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    258\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmaximize\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    259\u001B[0m \u001B[43m        \u001B[49m\u001B[43mforeach\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mforeach\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    260\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcapturable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    261\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdifferentiable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfused\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroup\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfused\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    263\u001B[0m \u001B[43m        \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mgrad_scale\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfound_inf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/Desktop/Academic/4B/CS 480/.venv/lib/python3.13/site-packages/torch/optim/optimizer.py:154\u001B[0m, in \u001B[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m disabled_func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Academic/4B/CS 480/.venv/lib/python3.13/site-packages/torch/optim/adam.py:876\u001B[0m, in \u001B[0;36madam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001B[0m\n\u001B[1;32m    873\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    874\u001B[0m     func \u001B[38;5;241m=\u001B[39m _single_tensor_adam\n\u001B[0;32m--> 876\u001B[0m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m    \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrads\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avgs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    880\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_exp_avg_sqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mamsgrad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mamsgrad\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhas_complex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhas_complex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta1\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta1\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbeta2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbeta2\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    887\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    889\u001B[0m \u001B[43m    \u001B[49m\u001B[43meps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmaximize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmaximize\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    891\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcapturable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcapturable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    892\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdifferentiable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdifferentiable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    893\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_scale\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgrad_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    894\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfound_inf\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfound_inf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    895\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/Academic/4B/CS 480/.venv/lib/python3.13/site-packages/torch/optim/adam.py:476\u001B[0m, in \u001B[0;36m_single_tensor_adam\u001B[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001B[0m\n\u001B[1;32m    474\u001B[0m         denom \u001B[38;5;241m=\u001B[39m (max_exp_avg_sqs[i]\u001B[38;5;241m.\u001B[39msqrt() \u001B[38;5;241m/\u001B[39m bias_correction2_sqrt)\u001B[38;5;241m.\u001B[39madd_(eps)\n\u001B[1;32m    475\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 476\u001B[0m         denom \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mexp_avg_sq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msqrt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbias_correction2_sqrt\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madd_\u001B[49m\u001B[43m(\u001B[49m\u001B[43meps\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    478\u001B[0m     param\u001B[38;5;241m.\u001B[39maddcdiv_(exp_avg, denom, value\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39mstep_size)\n\u001B[1;32m    480\u001B[0m \u001B[38;5;66;03m# Lastly, switch back to complex view\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for cf, method, k in tqdm(product([1, 3, 5, 8], ['Zscore', 'MinMax'], [0, 2, 4])):\n",
    "    model_name = f'CNN_LSTM_{method}_CF{cf}_pred_{k}'\n",
    "    if os.path.exists(os.path.join('.', 'trained_models', model_name)):\n",
    "        continue\n",
    "    train_data = FIDataset(DATA_DIR, method, cf, k=k, train=True)\n",
    "    test_data = FIDataset(DATA_DIR, method, cf, k=k, train=False)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER)\n",
    "\n",
    "    lob_model = CNN_LSTM()\n",
    "    lob_model.to(lob_model.device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(lob_model.parameters(), lr=LR)\n",
    "\n",
    "    batch_train(model_name, lob_model, criterion, optimizer, train_loader, test_loader, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6404f1fe7aef0eb",
   "metadata": {},
   "source": [
    "# Train CNN"
   ]
  },
  {
   "cell_type": "code",
   "id": "b811f267be1849e8",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-14T13:25:50.667473Z"
    }
   },
   "source": [
    "for cf, method, k in tqdm(product([1, 3, 5, 8], ['Zscore', 'MinMax'], [0, 2, 4])):\n",
    "    model_name = f'CNN_{method}_CF{cf}_pred_{k}'\n",
    "    if os.path.exists(os.path.join('.', 'trained_models', model_name)):\n",
    "        continue\n",
    "    train_data = FIDataset(DATA_DIR, method, cf, k=k, train=True)\n",
    "    test_data = FIDataset(DATA_DIR, method, cf, k=k, train=False)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER)\n",
    "\n",
    "    lob_model = CNN()\n",
    "    lob_model.to(lob_model.device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(lob_model.parameters(), lr=LR)\n",
    "\n",
    "    batch_train(model_name, lob_model, criterion, optimizer, train_loader, test_loader, EPOCHS)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Epoch 1/30,\n",
      "        Train Loss: 1.0337, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0479, Validation Acc:  0.4824,\n",
      "        Duration: 0:00:15.452172\n",
      "\n",
      "        Epoch 2/30,\n",
      "        Train Loss: 1.0141, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0462, Validation Acc:  0.4821,\n",
      "        Duration: 0:00:10.894898\n",
      "\n",
      "        Epoch 3/30,\n",
      "        Train Loss: 1.0122, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0455, Validation Acc:  0.4826,\n",
      "        Duration: 0:00:10.450777\n",
      "\n",
      "        Epoch 4/30,\n",
      "        Train Loss: 1.0112, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0456, Validation Acc:  0.4820,\n",
      "        Duration: 0:00:10.230100\n",
      "\n",
      "        Epoch 5/30,\n",
      "        Train Loss: 1.0103, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0470, Validation Acc:  0.4818,\n",
      "        Duration: 0:00:12.868573\n",
      "\n",
      "        Epoch 6/30,\n",
      "        Train Loss: 1.0099, Train Acc:  0.5227,\n",
      "        Validation Loss: 1.0447, Validation Acc:  0.4826,\n",
      "        Duration: 0:00:09.976105\n",
      "\n",
      "        Epoch 7/30,\n",
      "        Train Loss: 1.0093, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0450, Validation Acc:  0.4822,\n",
      "        Duration: 0:00:09.947415\n",
      "\n",
      "        Epoch 8/30,\n",
      "        Train Loss: 1.0087, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0462, Validation Acc:  0.4822,\n",
      "        Duration: 0:00:10.030456\n",
      "\n",
      "        Epoch 9/30,\n",
      "        Train Loss: 1.0082, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0456, Validation Acc:  0.4822,\n",
      "        Duration: 0:00:10.004670\n",
      "\n",
      "        Epoch 10/30,\n",
      "        Train Loss: 1.0078, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0454, Validation Acc:  0.4819,\n",
      "        Duration: 0:00:09.807198\n",
      "\n",
      "        Epoch 11/30,\n",
      "        Train Loss: 1.0074, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0456, Validation Acc:  0.4824,\n",
      "        Duration: 0:00:09.940820\n",
      "\n",
      "        Epoch 12/30,\n",
      "        Train Loss: 1.0071, Train Acc:  0.5228,\n",
      "        Validation Loss: 1.0453, Validation Acc:  0.4822,\n",
      "        Duration: 0:00:09.913187\n",
      "\n",
      "        Epoch 13/30,\n",
      "        Train Loss: 1.0069, Train Acc:  0.5230,\n",
      "        Validation Loss: 1.0464, Validation Acc:  0.4785,\n",
      "        Duration: 0:00:11.178728\n",
      "\n",
      "        Epoch 14/30,\n",
      "        Train Loss: 1.0064, Train Acc:  0.5229,\n",
      "        Validation Loss: 1.0468, Validation Acc:  0.4790,\n",
      "        Duration: 0:00:11.683671\n",
      "\n",
      "        Epoch 15/30,\n",
      "        Train Loss: 1.0063, Train Acc:  0.5232,\n",
      "        Validation Loss: 1.0472, Validation Acc:  0.4770,\n",
      "        Duration: 0:00:11.737489\n",
      "\n",
      "        Epoch 16/30,\n",
      "        Train Loss: 1.0063, Train Acc:  0.5231,\n",
      "        Validation Loss: 1.0465, Validation Acc:  0.4761,\n",
      "        Duration: 0:00:10.303065\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f59f4c62a363eb0e",
   "metadata": {},
   "source": [
    "# Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37058aa04d7c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cf, method, k in tqdm(product([1, 3, 5, 8], ['Zscore', 'MinMax'], [0, 2, 4])):\n",
    "    model_name = f'LSTM_{method}_CF{cf}_pred_{k}'\n",
    "    if os.path.exists(os.path.join('.', 'trained_models', model_name)):\n",
    "        continue\n",
    "    train_data = FIDataset(DATA_DIR, method, cf, k=k, train=True)\n",
    "    test_data = FIDataset(DATA_DIR, method, cf, k=k, train=False)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER)\n",
    "    lob_model = LSTM()\n",
    "    lob_model.to(lob_model.device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(lob_model.parameters(), lr=LR)\n",
    "\n",
    "    batch_train(model_name, lob_model, criterion, optimizer, train_loader, test_loader, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8942c92b4fffe542",
   "metadata": {},
   "source": [
    "# Train MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28744ad77ffc761",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cf, method, k in tqdm(product([1, 3, 5, 8], ['Zscore', 'MinMax'], [0, 2, 4])):\n",
    "    model_name = f'MLP_{method}_CF{cf}_pred_{k}'\n",
    "    if os.path.exists(os.path.join('.', 'trained_models', model_name)):\n",
    "        continue\n",
    "    train_data = FIDataset(DATA_DIR, method, cf, k=k, train=True)\n",
    "    test_data = FIDataset(DATA_DIR, method, cf, k=k, train=False)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKER)\n",
    "\n",
    "    lob_model = MLP()\n",
    "    lob_model.to(lob_model.device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(lob_model.parameters(), lr=LR)\n",
    "\n",
    "    batch_train(model_name, lob_model, criterion, optimizer, train_loader, test_loader, EPOCHS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
